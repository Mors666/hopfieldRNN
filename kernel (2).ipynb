{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": false,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\ntrain = pd.read_csv(\"../input/my-mnist/train.csv\", header=None)\ntest = pd.read_csv(\"../input/my-mnist/test.csv\", header=None)\ntrain = np.asarray(train)\ntest = np.asarray(test)\ntrain_labels = []  \ntest_labels = []\ntrain_images = []\ntest_images = []\nfor row in train:\n    train_labels.append(row[0])\n    train_images.append(row[1:]/ 255.0)\n    \nfor row in test:\n    test_labels.append(row[0])\n    test_images.append(row[1:]/ 255.0)\n    \nfor i in range(len(train_images)):\n    train_images[i] = train_images[i].reshape((28,28)).T\nfor i in range(len(test_images)):\n    test_images[i] = test_images[i].reshape((28,28)).T\ntrain_images =  np.asarray(train_images)\ntest_images =  np.asarray(test_images)\ntrain_labels =  np.asarray(train_labels)\ntest_labels =  np.asarray(test_labels)\n\nfrom keras.utils import np_utils\nprint(np.unique(train_labels, return_counts=True))\ntrain_labels = train_labels-1\ntest_labels = test_labels-1\n#train_labels = np_utils.to_categorical(train_labels, num_classes = 26)\n#test_labels = np_utils.to_categorical(test_labels, num_classes = 26)\nprint(train_images.shape)\n#print(np.unique(train_images, return_counts=True))\nprint(np.unique(train_labels, return_counts=True))\n#print(np.unique(train_images, return_counts=True))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "File b'../input/my-mnist/train.csv' does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6a70fc1ceb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/my-mnist/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/my-mnist/test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/my-mnist/train.csv' does not exist"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f724b9336955940d12cd2c20cd62527b3d62a458"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.imshow(train_images[8].reshape((28, 28)), cmap='gray')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fbe00e1f39db4f7e1c006eb88f03042d6003fb3f"
      },
      "cell_type": "markdown",
      "source": "Задание 1"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ada5f3bc2dc70b92f502145f477269eb585e680"
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow import keras\nfrom matplotlib import style\nstyle.use('seaborn')\n\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n\nlinear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Activation('relu')) # функция активации \nlinear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Activation('relu')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d86a3e25da115b620163774aa543a1ae8b387128"
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow import keras\nfrom matplotlib import style\nstyle.use('seaborn')\n\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n\nlinear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Activation('relu')) # функция активации \nlinear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Activation('relu')) # функция активации \nlinear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Activation('relu')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ae87f211f3f1323ae2f3ca70da17c37c30970f0d"
      },
      "cell_type": "markdown",
      "source": "Точность распознавания букв в случае трехслойной и двухслойной нейронной сети получилась примерно одинаковая.\nПопробуем проинициализировать веса случайными числами, а bias - нулями."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "25a0f6454d167c7a2667608d93372f002dc17223"
      },
      "cell_type": "code",
      "source": "linear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', bias_initializer='zeros'))# функция активации \nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', bias_initializer='zeros'))\nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', bias_initializer='zeros'))#скрытый слой из 100 нейронов\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax,kernel_initializer='glorot_uniform', bias_initializer='zeros')) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9f1fec27a3c94e23d9f3050fb799e5c74dd7c0b4"
      },
      "cell_type": "markdown",
      "source": "Качество ухудшилось, поэтому оставим веса и bias, как они были по умолчанию.\nПопробуем изменить параметр batch_size"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e65062c42f39c2f2c835a1e00481728660b163e"
      },
      "cell_type": "code",
      "source": "linear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu'))# функция активации \nlinear_model.add(keras.layers.Dense(100,activation='relu'))\nlinear_model.add(keras.layers.Dense(100,activation='relu'))#скрытый слой из 100 нейронов\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=64)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a92e371c4d0ae1eb9b448ea11b944b274ffe93b8"
      },
      "cell_type": "code",
      "source": "linear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu'))# функция активации \nlinear_model.add(keras.layers.Dense(100,activation='relu' ))\nlinear_model.add(keras.layers.Dense(100,activation='relu'))#скрытый слой из 100 нейронов\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax )) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b68892eeabd550e2aa598b884b44602b0ee8ba5a"
      },
      "cell_type": "markdown",
      "source": "Уменьшение параметра batch_size немного повысило качество модели, оставим значение 16.\nТеперь попробуем добавить batch normalization"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "579ad61bf9bdeef6a94822ea4cf35c6d0ace66e2"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.layers import BatchNormalization, Activation\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', \n                                    bias_initializer='zeros'))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', \n                                    bias_initializer='zeros'))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', \n                                    bias_initializer='zeros'))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax,kernel_initializer='glorot_uniform', bias_initializer='zeros')) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1cd297c785f232de3fa8f5aac12297c8b09d6765"
      },
      "cell_type": "markdown",
      "source": "Качество модели немного повысилось, поэтому оставим нормализацию.\nПробуем добавить регуляризацию"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9255fc491d0250cea88936dd4e052e9a84b2c974"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras import regularizers\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n#linear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))# функция активации \nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4f8e25e72ea2795c127ebec3baf52b73a28620ce"
      },
      "cell_type": "markdown",
      "source": "Регуляризация практически не повлияла на качество модели, но оставим ее.\nПопробуем добавить Dropout"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ceff6386ac833f862fa90d313dc71dc40ad374b2"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.layers import Dropout\n\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\n#linear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(Dropout(rate=0.2))\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\nlinear_model.add(Dropout(rate=0.2))\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\nlinear_model.add(Dropout(rate=0.2))\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "16942cd5a5c9daaa9cc95a137cbc5815dfb833a7"
      },
      "cell_type": "markdown",
      "source": "Dropout немного ухудшил качество модели, не будем его использовать.\nПопробуем применить разные оптимайзеры"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35420e6597b38fb538cb6fd73e6ccbebe240fec5"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.optimizers import RMSprop, Adam\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax )) # 26 - число классов\nlinear_model.compile(optimizer=RMSprop(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cce0c4b2873eab51b219d0880de1ec05227d3390"
      },
      "cell_type": "code",
      "source": "linear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=Adam(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d36f2c38ff55ee2bf4e2c46fcedef7459700503"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.optimizers import Adagrad\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax )) # 26 - число классов\nlinear_model.compile(optimizer=Adagrad(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d19d08fd9dc9fc4ccc4b49475e86539da8471f8f"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.optimizers import Adamax\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=Adamax(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0752e02c305449d13305d223f986d2ac98676b23"
      },
      "cell_type": "markdown",
      "source": "Из оптимайзеров самым подходящим получились Adam и RMSprop, качество - 89,5%. Оставим, например, Adam.\nТеперь попробуем поменять количество нейронов в слоях"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80753b2d10fdad92a98764b26aa5a0c1fbfed7cd"
      },
      "cell_type": "code",
      "source": " linear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(512,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(512,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(512,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=Adam(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9c4205e3c2e907ed08d2fe795aecab29beeaec3c"
      },
      "cell_type": "markdown",
      "source": "С увеличением числа нейронов качество модели улучшилось.\nПопробуем изменить количество слоев"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "609fe275ece398bcb750ff8fa44760f0f81f2f46"
      },
      "cell_type": "code",
      "source": "#5 слев\nlinear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(100,activation='relu',kernel_initializer='glorot_uniform', \n                                    bias_initializer='zeros'))\nlinear_model.add(BatchNormalization())\n \n \n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation=tf.nn.softmax)) # 26 - число классов\nlinear_model.compile(optimizer=Adam(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1f38cd9d674b33459df9cb5b4581bee27969c8d1"
      },
      "cell_type": "markdown",
      "source": "С увеличением числа слоев качество модели не улучшилось, можно оставить 3 слоя.\nПопробуем изменить функцию активации выходного слоя."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30d1715557e476f19d80385c126aa5ff14784588"
      },
      "cell_type": "code",
      "source": "linear_model = keras.Sequential()\n\nlinear_model.add(keras.layers.Flatten(input_shape=(28, 28))) # перевод данных в вектор размерности 28*28=784 (построчно)\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Dense(100)) # скрытый слой из 100 нейронов\nlinear_model.add(keras.layers.Dense(512,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(512,activation='relu', kernel_regularizer=regularizers.l2(0.00)))\nlinear_model.add(BatchNormalization())\nlinear_model.add(keras.layers.Dense(512,activation='relu', kernel_regularizer=regularizers.l2(0.00)))#скрытый слой из 100 нейронов\nlinear_model.add(BatchNormalization())\n#linear_model.add(keras.layers.Activation('relu',kernel_initializer='glorot_uniform', bias_initializer='zeros')) # функция активации \n\nlinear_model.add(keras.layers.Dense(26, activation= 'sigmoid')) # 26 - число классов\nlinear_model.compile(optimizer=Adam(lr=0.001), \n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\nlinear_model.fit(train_images, train_labels, epochs=10, verbose=0, batch_size=16)\ntest_loss, test_acc = linear_model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc, '\\nTest loss:', test_loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "30f702d73453652a6b28f1ce6ff1fbddbc3d06ff"
      },
      "cell_type": "markdown",
      "source": "В качестве функции активации выходного слоя лучше подходит сигмоид, в итоге получаем точность около 90%\n "
    },
    {
      "metadata": {
        "_uuid": "2d9e1de6b55f12a753da1ded0cc9d82262708eb8"
      },
      "cell_type": "markdown",
      "source": "Задание 2"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a959e96c7c3cbd0084df610c89c4a84d476b3a9"
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\nimport itertools\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(test_labels, linear_model.predict_classes(test_images))\nnp.set_printoptions(precision=2)\n\n\n# Plot normalized confusion matrix\n#plt.figure()\nplot_confusion_matrix(cnf_matrix,  normalize=True,classes=np.arange(1, 27),\n                      title='Normalized confusion matrix')\n\nplt.show()\nstyle.use('default')\n'''plot_confusion_matrix(cm=metrics.confusion_matrix(test_labels, \n                                                  linear_model.predict_classes(test_images)),\n                      target_names=np.arange(1, 26),\n                      normalize=True)'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6e6239a175a1f08861eb75a3a83dda1c7a725da3"
      },
      "cell_type": "markdown",
      "source": "Путаются между собой: i-l, g-q. Это логично, так как эти буквы очень схожи между собой"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0dd9146a746efb915110c879ad17a12e1808c27"
      },
      "cell_type": "code",
      "source": "predictions = linear_model.predict_classes(test_images)\nincorrect = np.nonzero(predicted!=test_labels)[0]\nprint(incorrect)\nplt.figure()\nfor i,incorrect in enumerate(incorrect):\n    plt.subplot(10,10,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(test_images[incorrect].reshape((28, 28)), cmap='gray_r')\n    plt.title((predictions[incorrect],test_labels[incorrect]))\n    plt.xlabel(i)\n    plt.grid(False)\n    if i >=4:\n        break\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e604e7cd77813efc24fd4ec502833c95577d5af9"
      },
      "cell_type": "code",
      "source": "accuracy = []\nfor i in range(26):\n    true = np.nonzero(predictions == test_labels[i] )[0]\n    false = np.nonzero(predictions != test_labels[i] )[0]\n    accuracy.append(len(true)/(len(true)+len(false)))\n    print(accuracy[i])\nprint(\"min: \",np.min(accuracy))\nprint(\"max: \",np.max(accuracy))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf794cab3b58ac9a7b483cb54913b1abe94fbf8c"
      },
      "cell_type": "markdown",
      "source": "все  буквы определяются с примерно одинаковой точностью, невелика разница между самой лучшей и самой худшей точностью детекции"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d319970a0c8cd025fc189a3af1422505ef0d508"
      },
      "cell_type": "code",
      "source": "accuracy = []\nfor i in range(len(test_labels)):\n    if test_labels[i]==25:\n        true = np.nonzero(predictions == test_labels[i] )[0]\n        false = np.nonzero(predictions != test_labels[i] )[0]\n        accuracy.append(len(true)/(len(true)+len(false)))\n        #print(accuracy[i])\nprint(\"mean: \",np.mean(accuracy))\n ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e5f11f0edb317bd96b4d073d292f72689ce901ca"
      },
      "cell_type": "markdown",
      "source": "Задание 3"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5a6a2b3f803289db2ae21b31f8d7ed3c2759ab5"
      },
      "cell_type": "code",
      "source": "from PIL import Image\nimage = Image.open(\"temp.jpg\")",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}